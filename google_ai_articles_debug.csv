Title,Link,Content
How songwriter Justin Tranter helped evolve Music AI Sandbox,https://blog.google/technology/ai/how-songwriter-justin-tranter-helped-evolve-music-ai-sandbox/,"We believe in the power of technology to help people express their creativity. That’s why we launched Lab Sessions, hands-on collaborations that explore how technology can support creative endeavors. For our latest Lab Session, we teamed up with a true powerhouse in the music industry, Grammy-nominated songwriter Justin Tranter. Together, our goal was to help shape Music AI Sandbox — a suite of generative music tools designed to amplify the creativity of songwriters and musicians everywhere.
“As a songwriter, of course I was apprehensive at first — I’m very protective of my community,” Justin says. Songwriters are, after all, the heart and soul of the music ecosystem, shaping culture through their artistry.
As Justin began experimenting with the tools, their perspective shifted. “Through working with Google and YouTube, it became evident that Music AI Sandbox empowers songwriters,” says Justin. Using these tools inspired new ideas and opened up new creative avenues, enhancing Justin’s craft.
We spent 36 hours with Justin over six weeks, working side-by-side to explore the possibilities of Music AI Sandbox. Together, we examined everything from creating and transforming new sounds to structuring songs and crafting lyrics that fit specific melodies. Justin shared their insights into the songwriting process, and our team used that feedback to build and test prototypes in real-time, constantly refining our concepts and approach. The culmination of this collaboration was ""Silent Tension,” a song created by Justin, vocalist and songwriter Blush, and producer Shawn Wasabi at the legendary Village Studios in Los Angeles. It was important to Justin that this final track showcased the fusion of human and AI collaboration.
Music AI Sandbox offers a glimpse into a future where technology complements and amplifies human creativity, enabling artists to push boundaries while staying true to their unique artistic visions. We hope this Lab Session with Justin Tranter inspires other musicians and songwriters to explore the limitless possibilities at the intersection of music and AI.
Visit us at Labs.google to discover more innovative tools, connect with us on social media (@labsdotgoogle), or join our Discord community at discord.gg/googlelabs. You can also check out all of our Lab Sessions at labs.google/sessions."
A new era of discovery,https://blog.google/technology/ai/a-new-era-of-discovery/,"Editor’s note: Today in London, Google DeepMind and the Royal Society co-hosted the inaugural AI for Science Forum, which brought together Nobel laureates, the scientific community, policymakers, and industry leaders to explore the transformative potential of AI to drive scientific breakthroughs, address the world's most pressing challenges, and lead to a new era of discovery.
Google’s Senior Vice President for Research, Technology and Society, James Manyika, delivered the opening address; what follows is a transcript of his remarks, as prepared for delivery.


AI’s impact in science has been in the headlines lately, but the potential of AI to advance science has long been a motivating force for many in the field, dating back to early AI researchers, such as Alan Turing and Christopher Longuet-Higgins, and to many in recent decades including my colleagues at Google DeepMind and Google Research.
The excitement around AI and science is not because of a belief that AI is a replacement for scientists, but because many confounding problems in science benefit from the use of computational techniques — thus making AI a powerful tool to assist scientists.
We saw early signs of that assistive potential with Hodgkin and Huxley’s use of computational approaches to describe how nerve impulses travel along neurons, work that would win them the Nobel Prize in 1963.
Fast forward to my colleagues Demis Hassabis, John Jumper and the AlphaFold team whose work using AI recently won the Nobel Prize in Chemistry, solving the “protein-folding problem” posed by Nobel laureate Christian Anfinsen in the 1970s.
I’ll start with speed. In some areas of science, increasingly capable AI is making it possible for us to condense hundreds or even thousands of years of research into a few years, months, or even days.
AI is also helping expand the scope of research – enabling scientists to look at many things at once — and in new ways — rather than one by one.
AI advances — along with access to insights from using it — are enabling many more people to participate in research, so that we can further accelerate scientific discovery.
Let me share briefly a few examples of how AI is enabling landmark advances, starting with AlphaFold:
With AlphaFold, over the course of a year my colleagues were able to predict the structure of nearly every protein known to science — over 200 million of them. And with Alphafold 3, they have extended beyond proteins to all of life’s bio-molectures including DNA, RNA and ligands.
To date, AlphaFold has been used by more than 2M researchers in more than 190 countries, working on problems ranging from neglected diseases to drug-resistant bacteria.
AlphaMissense, which builds on AlphaFold, enabled my colleagues to categorize almost 90% of 71M possible missense variants — single letter substitutions in DNA — as likely pathogenic or likely benign. By contrast, only 0.1% have been confirmed by human experts, albeit in more detail.
When the human genome was initially sequenced — an incredible achievement — it was based on a single genomic assembly.
Last year, my colleagues in Google Research, using AI tools and working with a consortium of academic collaborators, released the first draft reference human pangenome.
This was based on 47 genomic assemblies, thus better representing human genetic diversity.
In neuroscience, a 10-year collaboration between my colleagues in Google Research, the Max Planck Institute, and the Lichtman Lab at Harvard, recently produced a nano-scale mapping of a piece of the human brain — that is a level of detail never previously achieved.
This project revealed never-before-seen structures in the human brain that may change our understanding of how the human brain works. This will perhaps lead us to new approaches to understanding and tackling neurological diseases like Alzheimer's and others. The full mapping has been made publicly available for researchers to build on
Beyond the life sciences, we’re seeing progress in other domains.
In a landmark achievement for climate modeling, we combined machine learning with a traditional, physics-based approach to build NeuralGCM.
This allows us to simulate the atmosphere more accurately and efficiently — NeuralGCM can simulate over 70,000 days of the atmosphere in the time it would take a state-of-the-art, physics-based model to simulate only 19 days.
There are other similar breakthroughs such as the work by my colleagues at Google DeepMind on GraphCast, a state-of-the-art AI model that predicts weather conditions up to 10 days in advance more accurately and much faster than the industry gold-standard weather simulation system.
Our Quantum AI team is making progress on questions that previously were the realm of science fiction, like studying the characteristics of traversable wormholes.
This opens up new possibilities for testing quantum gravity theories originally posed with the Einstein-Rosen bridge almost ninety years ago.
In fact, Quantum is an area where we’re beginning to see promising bidirectional reinforcement between AI and science.
In one direction, AI is advancing our progress in quantum computing — in the other, quantum is helping advance research in AI.
There are many other such examples that we are working on in material science, fusion, mathematics and more – all of these, in collaboration with many academic scientists.
Beyond such breakthroughs, AI is also advancing science in ways that are already providing tangible benefits for real people in areas like climate and healthcare.
Let me start with an example from climate adaptation. Flood forecasting is a more frequent and urgent problem due to climate change. Now, advances in AI have enabled us to fill in large gaps in data to predict riverine flooding up to 7 days in advance with the same accuracy as nowcasts. After an initial pilot in Bangladesh, our early-warning platform — Flood Hub — now covers over 100 countries and 700 million people.
And for an example in climate mitigation, consider the following: the formation of contrails has long been a known driver of emissions in aviation — accounting for as much as 35% of aviation's global warming impact.
My colleagues in Google Research developed an AI model that predicts where contrails are likely to form, and in partnership with American Airlines, tested it on 70 flights. We measured the impact and found a 54% reduction in emissions.
Similarly, AI offers much promise for disease detection. For example, eight years ago, Google researchers found that AI could help accurately interpret retinal scans to detect diabetic retinopathy, a preventable cause of blindness that affects roughly 100 million people.
We developed a screening tool that has been used in more than 600,000 screenings worldwide. And new partnerships in Thailand and India will enable 6 million screenings over the next decade.
We have been implementing other examples including in tuberculosis, colorectal cancer, breast cancer and maternal health.
Despite the progress, this is just the beginning. There’s so much still to do.
I see three key areas to focus on to fully realize AI’s potential to help advance science and bring tangible societal benefits:
First, we need to continue to make progress on AI’s current limitations and shortcomings — and to increase AI’s capabilities to be able to assist in developing novel scientific concepts, theories, experiments and more.
Second, we need a sustained commitment to the scientific method and to responsible approaches to using AI to advance science.
We need scientists, ethicists and safety experts — like many in this room — working together to address the risks most particular to science, like viruses and bioweapons, as well as challenges like bias in data sets, privacy preservation, and environmental impacts.
Third, we need to prioritize making AI-enabled research, tools and resources more accessible to more scientists in more places — and to make sure the progress we make benefits people everywhere.
I am excited about what lies ahead in this new era of discovery.
There is so much we can do together to build tools that help advance science to benefit everyone.
And there is so much we can do to enable the amazing scientists here and elsewhere in their work — we’ll hear from some of them today."
Google.org’s $20 million fund for AI and science,https://blog.google/outreach-initiatives/google-org/google-org-science-ai-funding/,"The recent award to Demis Hassabis and John Jumper of the Nobel Prize (® the Nobel Foundation) in Chemistry, for AlphaFold’s contributions to protein structure prediction, is proof that AI can deliver incredible breakthroughs for scientists. Already, more than 2 million researchers across 190 countries have used AlphaFold to help accelerate the fight against malaria, combat a widespread and deadly parasitic disease and pave the way for new Parkinson’s treatments. And AI is enabling our progress across a range of scientific domains from hydrology to neuro and climate sciences.
But for AI to enable the next generation of scientific breakthroughs, scientists need necessary funding, computing power, cross-domain expertise and access to infrastructure including foundational datasets, like the Protein Data Bank that fueled the work with AlphaFold.
That’s why today, at the inaugural AI for Science Forum hosted by Google DeepMind and the Royal Society, Google.org announced $20 million in funding to support academic and nonprofit organizations around the world that are using AI to address increasingly complex problems at the intersections of different disciplines of science. Fields such as rare and neglected disease research, experimental biology, materials science and sustainability all show promise.
We'll work with leaders internally across our Google DeepMind, Google Research and other AI-focused teams as well as external experts to identify and announce organizations. We will also provide $2 million in Google Cloud Credits and pro bono technical expertise from Googlers.
This funding builds on the more than $200 million Google.org has provided to organizations using AI to accelerate their scientific work over the last five years, including Materiom building novel plastics; the Women's Cancer Institute (coordinated by Institut Curie) improving the detection, treatment and understanding of women's cancer; and Doctors Without Borders helping to stamp out antibiotic resistance.
Time and again, funding, technology and collaboration have come together to drive scientific discovery. We’re hopeful that this new funding helps incubate more Nobel-level achievements that will improve the lives of millions of people — and that other philanthropic, public and private funders join us by investing in long-term, meaningful outcomes that exemplify AI's ability to enable science at digital speed."
Announcing the 2024 Google PhD Fellows,https://blog.google/technology/research/google-phd-fellowship-program-2024/,"It’s been 15 years since Google launched the PhD Fellowship Program to recognize and support outstanding graduate students pursuing exceptional research in computer science and related fields.
At Google, we firmly believe in the connection between scientific advancement and social impact. We’re committed to supporting PhD students’ fundamental research through funding and mentorship, and see it as vital to transforming the way we approach the toughest problems across foundational science. Over the past 15 years, Google’s PhD Fellowship Program has supported over 800 graduate students from over 210 universities in 53 countries across Africa, Australia, East Asia, Europe, India, Latin America, New Zealand, North America and Southeast Asia.
I'm thrilled the program has been able to champion PhD students at the forefront of scientific advancement around the globe. And today, I'm excited to announce the recipients of the 2024 Google PhD Fellowship program. See the complete list of Google PhD Fellowship recipients for 2024.
As we welcome the 2024 Google PhD Fellows, I also want to take a moment to reflect on the journeys of some of our earliest fellows. Our program fosters a vibrant community of scholars who have gone on to shape the landscape of computer science across academia, industry and entrepreneurship. Their experiences and accomplishments exemplify the impact that passionate researchers can have on technology and society. Here’s what nine Google PhD Fellows from the program’s first year had to say about their experiences."
"A golden age for research: broader scope, faster cycles, greater impact",https://blog.google/technology/research/what-is-google-research/,"We live in a golden age for research.
Never before have we had the opportunity to make such rapid advances in computer science, and apply them so quickly to global-scale challenges, in a way that can help people in their daily lives. Since the start of my career, I’ve been excited by the “magic cycle” of research, where real-world challenges motivate new foundational and applied research, which in turn has a positive impact in the real world. Today, with the right infrastructure, talent and approach, we’re able not only to make rapid breakthroughs in everything from AI to algorithms to computing infrastructure, but to put those technologies to work to improve people’s daily lives and have societal impact faster than ever before, sometimes in a matter of months.
I’m seeing this firsthand as I’ve recently stepped up to lead Google Research, so I wanted to share a perspective on the incredible progress we’re seeing — and how important research is in driving helpful innovation.
Google itself in fact began with research. “The anatomy of a large-scale hypertextual Web search engine,” published in 1998, explored how PageRank could provide a fundamentally better way to find info on the web, But it didn’t stop with a research paper — it was applying that research that produced Google. Over the past 26 years, that approach to implementing research — quickly — has transformed not only our company, but also how people can interact with the world’s information. Indeed, much of the rapid progress in AI we see all around us today grew from Google Research’s invention of the Transformer.
In all of our research, we ask ourselves: How can we make a step change, not just incremental? What’s impossible today, that we could make possible? And what is the greatest impact we can have — how can this make a real difference in the world?
Google Research today includes fundamental and applied work in foundational machine learning and algorithms, computing systems and quantum AI, and science, AI & societal impact. And across all these domains, we run initiatives on efficiency in machine learning, factuality & grounding in AI systems, and new data techniques.
We motivate our research by going after the biggest questions that matter to advance science and make a difference to people and to communities globally. What are the most effective ways to mitigate climate change? How can we help make billions of people healthier? How can we enable new experiences? And to do all this, can we break through limitations in computing and AI systems? Each of those becomes an inspiring research challenge — and in so many cases we’ve already translated research into solutions.
For example, to address climate change, in a trial with American Airlines we used AI to help reduce contrails by 54%, demonstrating that airlines can verifiably avoid contrails and thereby reduce their climate impact. To help address the growing wildfire crisis, we partnered with leading wildfire authorities to develop FireSat, an upcoming AI-powered global satellite constellation to detect and track wildfires the size of a classroom — within 20 minutes. And consider flood forecasting — when our team at Google Research began the project in 2018, experts I met with said it was likely impossible to forecast riverine floods. But by developing AI that can build a global hydrologic model, we’ve not only proven it’s possible, but applied it to provide communities accurate early warnings and help save lives.
Meanwhile, to support health and wellbeing, we’ve developed AI that can help screen for breast cancer and colorectal cancer, help prevent blindness at scale, spot potential skin conditions and detect diseases based on the sound of coughs. We’re still in the earliest days of AI breakthroughs and genomics research, and yet we’ve made progress with Large Language Models for the medical domain and we’re already poised to improve the health care for hundreds of millions of people.
But perhaps one of the biggest undertakings involves advancing computing itself, and how it can fundamentally alter the scope of problem-solving. We’ve developed state-of-the-art attention models and use graph mining to improve retrieval quality. We’re also working on approaches to grounding large language models, such as by training models to rely on source documents for summarization and evaluating factual consistency. This research has led to improvements like the double-check feature in the Gemini app. We’ve made AI more efficient with research on speculative decoding, efficient inference techniques, and cascades, and we’ve helped improve privacy with federated learning and differential privacy. And our quantum computing team just published new results in Nature affirming that as we reduce the error rate in our quantum processors, we reach levels of computation that can’t be matched by even the world’s most powerful classical computers — putting us on track to crack open an entirely new computational capability for the world.
These are just a few examples of the type of work done across Google Research.
Of course, as we turn research towards impact, we’re acutely aware that technology is not automatically beneficial — you can't ""invent it and forget it,"" simply releasing powerful technologies on the naive assumption that they will be helpful. It requires careful stewardship, partnership and a fundamentally human-centric view of how to design and guide emerging technologies. That’s one reason we do our research in partnership with a multitude of researchers in academia and many others, while creating tools and best practices that support a truly global research ecosystem with the aim of steering new technologies towards beneficial outcomes. We actively engage in advancing socio-technical research to bolster our AI principles — including on equitable datasets, interpretability, and algorithmic fairness — and there’s important work ahead to make our AI models even more efficient, factual, robust and safe.
We have the greatest impact when we’re working with research partners. Since 2005, Google has worked with more than 1,000 research institutions and invested over $400 million dollars in academic research worldwide, much of this led by Google Research. We find experts across disciplines, roll up our sleeves, dive into the research, and make scientific advances together. In our connectomics research, we’ve partnered with Harvard to use AI to make the most detailed mapping yet of neurons in the human brain, revealing newly discovered structures — all towards helping scientists understand fundamental processes such as thought, learning and memory. Google Research also engaged in a first-of-its-kind collaboration with Howard University and other HBCUs to build a high-quality African-American English (AAE) speech dataset that Google — and others — will use to improve speech products. This is related to our overall effort to reduce barriers and better serve communities by enabling technology to work in many more languages.
With our partners, and through Google’s own products, we use our research advances to benefit billions of people. For example, as populations swell and shift in the Global South, millions of people’s buildings aren’t represented on any map, and they risk missing out on essentials like electricity, healthcare and mail delivery. So Google Research in Africa has used AI to make big improvements to the Open Buildings dataset — transforming blurry, low-res satellite imagery into useful, high-res building outlines so partners like the World Bank, the World Resources Institute, UN Habitat, WorldPop and Sunbird AI can use it to ensure global development includes everyone. Along with our SKAI effort, this has helped our partnership with the UN to boost damage assessment.
In another sphere, our Operations Research team recently showed how cargo shippers could double their profit, deliver 13% more containers and use 15% fewer ships. This is not only helpful for businesses, but good for supply chains globally.
Finally, we of course partner extensively with product teams to drive innovation across Google — and our responsibility also includes keeping an eye on the horizon, exploring the art of the possible, and imagining how we can apply our breakthrough technologies for maximum benefit in years to come.
We feel great urgency given the scope of problems facing humanity — but also great optimism because of what we’ve been able to do already. Our multi-decade track record shows that Google Research is second-to-none in delivering helpful advances. We’ve delivered breakthroughs that have shaped Google's identity as a company, helped inaugurate new fields in computer science, and advanced the frontiers of innovation and technology with thousands of publications. The advances we’ve shared are already assisting people – from their everyday tasks, to their most ambitious and imaginative endeavors — and addressing society’s most pressing challenges, from healthcare to education to climate change and climate science.
We'll keep sharing our breakthroughs on our Google Research blog, at conferences and at other events. We're eager to explore — and invent — the future alongside all the partners and communities we work with."
